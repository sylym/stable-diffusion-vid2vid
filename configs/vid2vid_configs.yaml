# 完整模型路径
pretrained_model_path: "./checkpoints/bocchiTheRock_v001"
# vae模型路径
pretrained_vae_path: "./checkpoints/bocchiTheRock_v001"


LoRA:
  # 是否使用loRA
  use_LoRA: False
  LoRA_data:
      # loRA模型路径
    - pretrained_LoRA_path: "./checkpoints/LoRA/aquaKonosubaLora_1.safetensors"
      # loRA模型权重
      LoRA_alpha: 1


pretrained_embedding:
  # 是否使用embedding
  use_pretrained_embedding: False
  pretrained_embedding_data:
      # embedding模型路径
    - pretrained_embedding_path: "./checkpoints/embeddings/EasyNegative.pt"
      # embedding模型关键词
      pretrained_embedding_prompt: "EasyNegative"


# 用于训练的提示 （人物主体 + 动作）
train_prompt: man,dancing
# 用于推理的正面提示,
inference_prompt: Bocchi,1girl,blue eyes,pink track jacket,long sleeves,pink sweatpants,black sneakers,
  pink long hair,bangs,hair between eyes,hair ornament,cube hair ornament,dancing,looking at viewer,
  aniscreen,anime coloring,4K wallpaper,(detailed face with beautiful eyes)+++,beautiful hands,simple white background
# 自动生成视频的正面提示（会将inference_prompt添加在提示开头）
prompt_generation: False
# 每帧生成关键词的概率阈值
prompt_generation_probability_threshold: 0.75
# 最多生成的prompt数量（以概率排序，优先满足概率阈值）
prompt_generation_num: 15
# 用于推理的负面提示
inference_negative_prompt: lowres,bad anatomy,(bad hands)++,text,error,(missing fingers)++,extra digit,(fewer digits)++,cropped,worst quality,low quality,normal quality,jpeg artifacts,signature,watermark,username,blurry
# 用于稳定视频的提示
ddim_prompt: ""


# 传入视频路径（用于训练和生成）
video_in_path: "./data/action.mp4"
# 传入视频的帧数（使用传入视频的20帧）
n_sample_frames: 20
# 传入视频的帧率（每2帧使用1帧）(传入视频帧数不少于 n_sample_frames * sample_frame_rate)
sample_frame_rate: 5


# 生成视频的宽度（小于等于传入视频）
video_width: 1024
# 生成视频的高度（小于等于传入视频）
video_height: 1024
# 生成视频的路径（无文件扩展名，会生成一个MP4视频和一个储存图片序列的同名文件夹）
video_out_path: "./outputs/Bocchi_action"


# 训练步数
num_train_steps: 500
# 推理步数
num_inference_steps: 50
# 与文字提示的相关度（越大越符合文字提示）
guidance_scale: 16
# 使用视频生成视频
use_vid2vid: False
# 与传入视频的相关度（越小与传入视频越像）
video_strength: 0.9
# 视频稳定
use_inv_latent: True
# 视频稳定的步数(越小与原视频越像，越大泛化能力越强)
num_inv_steps: 50
# 视频生成拆分数（将原视频拆分进行生成以减少显存使用）
num_splits: 20
# 使用conrolnet
use_conrolnet: True
# conrolnet参考视频预处理模式 [canny,depth,hed,mlsd,normal,openpose,scribble,seg]
controlnet_video_prepare_type: "openpose"
# conrolnet scale
controlnet_conditioning_scale: 1.0


# 高分修正
hiresfix: True
# 高分修正训练步数
hiresfix_num_train_steps: 100
# 重绘步数
hiresfix_num_inference_steps: 200
# 重绘与文字提示的相关度（越大越符合文字提示）
hiresfix_guidance_scale: 16
# 视频重绘程度（越大细节重绘越多）
hiresfix_strength: 0.5
# 高分修正使用视频稳定
hiresfix_use_inv_latent: False
# 视频稳定的步数
hiresfix_num_inv_steps: 10
# 高分修正拆分数（将原视频拆分进行生成以减少显存使用）
hiresfix_num_splits: 2
# 提高分辨率（超分到指定分辨率）
hiresfix_raise: True
# 高分修正次数
hiresfix_num: 1
# 多次高分修正时是否进行训练
hiresfix_with_train: False
# 高分修正使用conrolnet
hiresfix_use_conrolnet: True
# conrolnet参考视频预处理模式 [canny,depth,hed,mlsd,normal,openpose,scribble,seg]
hiresfix_controlnet_video_prepare_type: "hed"
# conrolnet scale
hiresfix_controlnet_conditioning_scale: 1.0


# 随机数种子
seed: 33
# 混合精度（no,fp16）（减少显存使用）
mixed_precision: "fp16"
# 是否使用8bit adam（减少显存使用,仅linux系统）
use_8bit_adam: False
# 是否使用xformers内存效率（减少显存使用）
enable_xformers_memory_efficient_attention: True
# 可用gpu
gpu_ids: "0"


# 是否使用预训练模型
use_pretraining_mode: False
# 是否只进行hiresfix
only_hiresfix: False
# 是否在only_hiresfix为True时使用hiresfix预训练模型
use_hiresfix_pretraining_model: False
# 生成结束后删除temp文件夹
delete_temp: False
# 生成视频过程中删除模型（减少在视频生成中使用的储存空间）
delete_checkpoints: True