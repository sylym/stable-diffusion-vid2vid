# 完整模型路径
pretrained_model_path: "./checkpoints/Counterfeit-V2.5"
# vae模型路径
pretrained_vae_path: "./checkpoints/Counterfeit-V2.5"


LoRA:
  # 是否使用loRA
  use_LoRA: True
  LoRA_data:
      # loRA模型路径
    - pretrained_LoRA_path: "./checkpoints/LoRA/majoNoTabitabiElaina_v30.safetensors"
      # loRA模型权重
      LoRA_alpha: 0.3


pretrained_embedding:
  # 是否使用embedding
  use_pretrained_embedding: True
  pretrained_embedding_data:
      # embedding模型路径
    - pretrained_embedding_path: "./checkpoints/embeddings/bad_prompt_version2.pt"
      # embedding模型关键词
      pretrained_embedding_prompt: "bad_prompt_version2"

    - pretrained_embedding_path: "./checkpoints/embeddings/bad_prompt.pt"
      pretrained_embedding_prompt: "bad_prompt"

    - pretrained_embedding_path: "./checkpoints/embeddings/bad-artist-anime.pt"
      pretrained_embedding_prompt: "bad-artist-anime"

    - pretrained_embedding_path: "./checkpoints/embeddings/bad-artist.pt"
      pretrained_embedding_prompt: "bad-artist"

    - pretrained_embedding_path: "./checkpoints/embeddings/EasyNegative.pt"
      pretrained_embedding_prompt: "EasyNegative"


# 用于训练的提示 （人物主体 + 动作）
train_prompt: man,kick
# 用于推理的正面提示,
inference_prompt: masterpiece,1girl,solo,(magenta_style_costume,majo_costume,witch_hat,boots,brooch)1.6,kick,simple white background
# 使用DeepDanbooru自动生成视频的正面提示（会将inference_prompt添加在提示开头）
prompt_generation: False
# 每帧生成关键词的概率阈值
prompt_generation_probability_threshold: 0.75
# 最多生成的prompt数量（以概率排序，优先满足概率阈值）
prompt_generation_num: 15
# 用于推理的负面提示
inference_negative_prompt: EasyNegative,nsfw,(low quality,worst quality)1.4,(bad anatomy)+,(inaccurate limb)1.2,bad composition,inaccurate eyes,extra digit,fewer digits,(extra arms)1.2
# 用于稳定视频的提示
ddim_prompt: ""


# 传入视频路径（用于训练和生成）
video_in_path: "./data/action2.mp4"
# 传入视频的帧数（使用传入视频的n_sample_frames帧）
n_sample_frames: 3
# 传入视频的帧率（每sample_frame_rate帧使用1帧）(传入视频帧数不少于 n_sample_frames * sample_frame_rate)
sample_frame_rate: 3


# 生成视频的宽度
video_width: 1024
# 生成视频的高度
video_height: 1024
# 生成视频的路径（无文件扩展名，会生成一个MP4视频和一个储存图片序列的同名文件夹）
video_out_path: "./outputs/elainaz_action"


# 训练步数
num_train_steps: 50
# 推理步数
num_inference_steps: 50
# 与文字提示的相关度（越大越符合文字提示）
guidance_scale: 16
# 使用视频生成视频
use_vid2vid: False
# 与传入视频的相关度（越小与传入视频越像）
video_strength: 0.9
# 视频稳定
use_inv_latent: True
# 视频稳定的步数(越小与原视频越像，越大泛化能力越强)
num_inv_steps: 50
# 视频生成拆分数（将原视频拆分进行生成以减少显存使用）
num_splits: 20

# 使用controlnet
use_controlnet: True
# controlnet相关参数
controlnet:
    # controlnet参考视频预处理模式 [canny,depth,hed,mlsd,normal,openpose,scribble,seg]
  - type: "openpose"
    # controlnet scale
    conditioning_scale: 1.0
    # controlnet输入视频路径（False使用video_in_path路径视频自动预处理）
    video_input: False

  - type: "hed"
    conditioning_scale: 1.0
    video_input: False



# 高分修正
hiresfix: True
# 高分修正训练步数
hiresfix_num_train_steps: 100
# 重绘步数
hiresfix_num_inference_steps: 200
# 重绘与文字提示的相关度（越大越符合文字提示）
hiresfix_guidance_scale: 16
# 视频重绘程度（越大细节重绘越多）
hiresfix_strength: 0.5
# 高分修正使用视频稳定
hiresfix_use_inv_latent: False
# 视频稳定的步数
hiresfix_num_inv_steps: 10
# 高分修正拆分数（将原视频拆分进行生成以减少显存使用）
hiresfix_num_splits: 3
# 提高分辨率（超分到指定分辨率）
hiresfix_raise: True
# 高分修正次数
hiresfix_num: 1
# 多次高分修正时是否进行训练
hiresfix_with_train: False

# 高分修正使用controlnet
hiresfix_use_controlnet: True
# controlnet相关参数
hiresfix_controlnet:
    # controlnet参考视频预处理模式 [canny,depth,hed,mlsd,normal,openpose,scribble,seg]
  - type: "openpose"
    # controlnet scale
    conditioning_scale: 1.0
    # controlnet输入视频路径（False使用video_in_path路径视频自动预处理）
    video_input: False

  - type: "hed"
    conditioning_scale: 1.0
    video_input: False


# 随机数种子
seed: 33
# 混合精度（no,fp16）（减少显存使用）
mixed_precision: "fp16"
# 是否使用8bit adam（减少显存使用,仅linux系统）
use_8bit_adam: False
# 是否使用xformers内存效率（减少显存使用）
enable_xformers_memory_efficient_attention: True
# 可用gpu
gpu_ids: "0"


# 是否使用预训练模型
use_pretraining_mode: True
# 是否只进行hiresfix
only_hiresfix: False
# 是否在only_hiresfix为True时使用hiresfix预训练模型
use_hiresfix_pretraining_model: False
# 生成结束后删除temp文件夹
delete_temp: False
# 生成视频过程中删除模型（减少在视频生成中使用的储存空间）
delete_checkpoints: False